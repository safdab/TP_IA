{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tp56_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rylcTyfU2mgP","colab_type":"text"},"cell_type":"markdown","source":["# CNN\n","##  Goal : \n","Initiation of use convolutional neural nets and realising basic image processing and classification tasks\n","\n"]},{"metadata":{"id":"URpCGosf3NHg","colab_type":"text"},"cell_type":"markdown","source":["#  CNN for computer vision"]},{"metadata":{"id":"B5H-JWu03gn8","colab_type":"code","outputId":"0930021a-9722-4a7c-84c3-c3ee477bfa15","executionInfo":{"status":"ok","timestamp":1552464951580,"user_tz":-60,"elapsed":178179,"user":{"displayName":"Daouda Barry","photoUrl":"","userId":"11998833459857343407"}},"colab":{"base_uri":"https://localhost:8080/","height":714}},"cell_type":"code","source":["\n","'''Trains a simple convnet on the MNIST dataset.\n","Gets to 99.25% test accuracy after 12 epochs\n","(there is still a lot of margin for parameter tuning).\n","16 seconds per epoch on a GRID K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 5   #12 initialement\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","#print('x_train shape:', x_train.shape)\n","#print(x_train.shape[0], 'train samples')\n","#print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# Subset of the data\n","\" nombre \"\n","data_slice = 10000\n","\n","x_train = x_train[:data_slice,:]\n","y_train = y_train[:data_slice,:]\n","x_test = x_test[:data_slice,:]\n","y_test = y_test[:data_slice,:]\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 'Output' :(3000, 784)\n","# 'Output' :(3000, 10)\n","#Strides par defaut est égal à la taille du kernel donc à 2 dans notre cas\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # nombre de param (3*3 +1)*32 \n","model.add(Conv2D(64, (3, 3), activation='relu')) \n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax')) # softmax pour être homogène à une proba\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","model.summary()\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (10000, 28, 28, 1)\n","10000 train samples\n","10000 test samples\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_29 (Conv2D)           (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 9216)              0         \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 128)               1179776   \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 1,199,882\n","Trainable params: 1,199,882\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 10000 samples, validate on 10000 samples\n","Epoch 1/5\n","10000/10000 [==============================] - 35s 4ms/step - loss: 0.7668 - acc: 0.7514 - val_loss: 0.2559 - val_acc: 0.9222\n","Epoch 2/5\n","10000/10000 [==============================] - 34s 3ms/step - loss: 0.2513 - acc: 0.9284 - val_loss: 0.1236 - val_acc: 0.9606\n","Epoch 3/5\n","10000/10000 [==============================] - 33s 3ms/step - loss: 0.1637 - acc: 0.9519 - val_loss: 0.1154 - val_acc: 0.9629\n","Epoch 4/5\n","10000/10000 [==============================] - 33s 3ms/step - loss: 0.1243 - acc: 0.9619 - val_loss: 0.0846 - val_acc: 0.9733\n","Epoch 5/5\n","10000/10000 [==============================] - 33s 3ms/step - loss: 0.1033 - acc: 0.9690 - val_loss: 0.0770 - val_acc: 0.9771\n","Test loss: 0.07703077969281003\n","Test accuracy: 0.9771\n"],"name":"stdout"}]},{"metadata":{"id":"_bj_Bo8wEDFS","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"TIIlBj7s9eTg","colab_type":"text"},"cell_type":"markdown","source":["# La taille des couches de sorties est divisée par la valeur du  strides de la couche de max-pooling. \n","Par exemple pour un strides égal à 2 la taille de la sortie de cette couche passe de (24,24) à (12,12). Pour avoir la même en entrée er en sortie de la couche de max-pooling on met strides =1 et le padding='same'\n","\n","Nombre de paramètres d'une couche\n","(nombre de couches en entréeXtaille_kernel +1)nombre de couches en sortie "]},{"metadata":{"id":"GGG7zhAy7vme","colab_type":"text"},"cell_type":"markdown","source":["# After removing the max-pooling"]},{"metadata":{"id":"yLognQJg4t2L","colab_type":"code","outputId":"db8ce4c1-a009-4e91-f396-bb2253be2fa1","executionInfo":{"status":"ok","timestamp":1552476825351,"user_tz":-60,"elapsed":22613,"user":{"displayName":"Daouda Barry","photoUrl":"","userId":"11998833459857343407"}},"colab":{"base_uri":"https://localhost:8080/","height":766}},"cell_type":"code","source":["\n","'''Trains a simple convnet on the MNIST dataset.\n","Gets to 99.25% test accuracy after 12 epochs\n","(there is still a lot of margin for parameter tuning).\n","16 seconds per epoch on a GRID K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 5   #12 initialement\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","#print('x_train shape:', x_train.shape)\n","#print(x_train.shape[0], 'train samples')\n","#print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# Subset of the data\n","\" nombre \"\n","data_slice = 10000\n","\n","x_train = x_train[:data_slice,:]\n","y_train = y_train[:data_slice,:]\n","x_test = x_test[:data_slice,:]\n","y_test = y_test[:data_slice,:]\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 'Output' :(3000, 784)\n","# 'Output' :(3000, 10)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu')) # nombre de param 3*3*32*(3 couleurs)\n","#model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax')) # softmax pour être homogène à une proba\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","model.summary()\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":102,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_train shape: (10000, 28, 28, 1)\n","10000 train samples\n","10000 test samples\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 36864)             0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 128)               4718720   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 4,738,826\n","Trainable params: 4,738,826\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 10000 samples, validate on 10000 samples\n","Epoch 1/5\n","10000/10000 [==============================] - 9s 874us/step - loss: 0.6719 - acc: 0.7905 - val_loss: 0.2639 - val_acc: 0.9182\n","Epoch 2/5\n","10000/10000 [==============================] - 3s 265us/step - loss: 0.2278 - acc: 0.9325 - val_loss: 0.1574 - val_acc: 0.9510\n","Epoch 3/5\n","10000/10000 [==============================] - 3s 265us/step - loss: 0.1563 - acc: 0.9535 - val_loss: 0.1035 - val_acc: 0.9686\n","Epoch 4/5\n","10000/10000 [==============================] - 3s 262us/step - loss: 0.1173 - acc: 0.9626 - val_loss: 0.0992 - val_acc: 0.9692\n","Epoch 5/5\n","10000/10000 [==============================] - 3s 262us/step - loss: 0.0907 - acc: 0.9724 - val_loss: 0.0976 - val_acc: 0.9694\n","Test loss: 0.09757052215447183\n","Test accuracy: 0.9694\n"],"name":"stdout"}]},{"metadata":{"id":"Kx3bkEcjGZzq","colab_type":"text"},"cell_type":"markdown","source":["La couche de max-pooling i nfluence la taille du réseaux dans le cas où le strides est différent de 1 sinon rien ne change"]},{"metadata":{"id":"xLQgTWMlW7Km","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"hQtg25NkW5N7","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"tYUAbh6GW3SY","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"jTruN34zHRXx","colab_type":"text"},"cell_type":"markdown","source":["# Training a convnet on a small dataset\n","Writing a classifier that should classify images whether they depict a dog or a cat"]},{"metadata":{"id":"gAGEcH1H2Oiu","colab_type":"code","colab":{}},"cell_type":"code","source":["!unzip catsDogsSmall.zip -d CatsDogs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vsmrDuWnJsil","colab_type":"code","colab":{}},"cell_type":"code","source":["import os, cv2, re, random\n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import img_to_array, load_img\n","from keras import layers, models, optimizers\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import keras\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TLZ5k1IIJ-Ao","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title\n","from os import listdir\n","\n","\n","dirPath = \"./CatsDogs/\"\n","AllImages = listdir(dirPath) #toutes les images\n","# Split data into train and test set\n","img_rows, img_cols = 100, 100\n","\n","AllImages.remove(\"__MACOSX\")\n","x = []  #liste des images\n","y = []  # liste des labels\n","\n","for i in AllImages :\n","  img = cv2.imread(dirPath + i)\n","  #print(dirPath + i)\n","  resized_image = cv2.resize(img, (img_rows,img_cols)) \n","  x.append(resized_image)\n","     \n","  if( \"cat\" in i ):\n","    y.append(0)\n","  elif (\"dog\" in i):\n","    y.append(1)\n","    \n","x = np.asarray(x)\n","y = np.asarray(y)\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)\n","x_train=x_train.astype(float)/255.0  \n","x_test=x_test.astype(float)/255.0\n","\n","#print(_train)     \n","           \n","\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"iQj-mggquO7Y","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2Zctqkc2uOGy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1072},"outputId":"f65d4e8a-8478-4a27-986d-b54cf7127273","executionInfo":{"status":"error","timestamp":1552478081421,"user_tz":-60,"elapsed":588,"user":{"displayName":"Daouda Barry","photoUrl":"","userId":"11998833459857343407"}}},"cell_type":"code","source":["num_classes = 2\n","input_shape = (100,100,3)\n","batch_size = 16\n","epochs = 5\n","\n","# Transformation des listes de labels en des numpy array\n","y_train = np.asarray(y_train)\n","y_test  = np.asarray(y_test)\n","x_train = np.asarray(x_train)\n","x_test = np.asarray(x_test)\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu')) # nombre de param 3*3*32*(3 couleurs)\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax')) # softmax pour être homogène à une proba\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","model.summary()\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":125,"outputs":[{"output_type":"stream","text":["x_train shape: (1200, 100, 100, 3)\n","1200 train samples\n","800 test samples\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_26 (Conv2D)           (None, 98, 98, 32)        896       \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 96, 96, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","flatten_12 (Flatten)         (None, 147456)            0         \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 128)               18874496  \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 1)                 129       \n","=================================================================\n","Total params: 18,894,017\n","Trainable params: 18,894,017\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-f46bc7d48c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_24 to have 2 dimensions, but got array with shape (1200, 2, 2)"]}]},{"metadata":{"id":"80FYfqJ95O0O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1754},"outputId":"7517b905-afc8-402c-a708-5629bf7fc14c","executionInfo":{"status":"ok","timestamp":1552478012467,"user_tz":-60,"elapsed":761,"user":{"displayName":"Daouda Barry","photoUrl":"","userId":"11998833459857343407"}}},"cell_type":"code","source":["print(model.predict(x_test[0:100]))"],"execution_count":124,"outputs":[{"output_type":"stream","text":["[[0.6805443  0.31945565]\n"," [0.4781531  0.5218469 ]\n"," [0.36281455 0.63718545]\n"," [0.00809409 0.9919059 ]\n"," [0.32088333 0.67911667]\n"," [0.6879795  0.31202048]\n"," [0.8954501  0.10454991]\n"," [0.52042186 0.4795781 ]\n"," [0.50992334 0.49007666]\n"," [0.6065713  0.39342865]\n"," [0.5116903  0.4883097 ]\n"," [0.17687728 0.8231227 ]\n"," [0.55270356 0.44729644]\n"," [0.68197584 0.31802413]\n"," [0.4770869  0.52291304]\n"," [0.4623642  0.5376358 ]\n"," [0.27762616 0.72237384]\n"," [0.59181315 0.40818688]\n"," [0.6895031  0.31049693]\n"," [0.59757966 0.4024203 ]\n"," [0.90125495 0.098745  ]\n"," [0.2371402  0.7628598 ]\n"," [0.1608015  0.83919847]\n"," [0.6003582  0.3996418 ]\n"," [0.9269105  0.07308948]\n"," [0.85392135 0.14607869]\n"," [0.02110796 0.9788921 ]\n"," [0.7471824  0.25281754]\n"," [0.82123125 0.17876872]\n"," [0.71165395 0.28834608]\n"," [0.65089506 0.34910494]\n"," [0.39130273 0.6086973 ]\n"," [0.64013946 0.3598605 ]\n"," [0.7045727  0.2954273 ]\n"," [0.4023148  0.5976852 ]\n"," [0.5321574  0.46784258]\n"," [0.8201763  0.17982374]\n"," [0.5775738  0.42242616]\n"," [0.47902483 0.5209752 ]\n"," [0.38717955 0.6128205 ]\n"," [0.93051594 0.06948407]\n"," [0.25784275 0.7421573 ]\n"," [0.18407674 0.8159232 ]\n"," [0.13151589 0.8684841 ]\n"," [0.6797436  0.32025647]\n"," [0.32745063 0.67254937]\n"," [0.2097248  0.79027516]\n"," [0.81524473 0.1847553 ]\n"," [0.47639075 0.5236092 ]\n"," [0.35952997 0.64047   ]\n"," [0.5603525  0.4396475 ]\n"," [0.5204363  0.4795637 ]\n"," [0.28377998 0.71622   ]\n"," [0.950744   0.04925607]\n"," [0.2473623  0.75263774]\n"," [0.6737354  0.32626462]\n"," [0.5441002  0.45589978]\n"," [0.39954156 0.6004584 ]\n"," [0.44205728 0.55794275]\n"," [0.765451   0.23454903]\n"," [0.63974696 0.36025307]\n"," [0.7952033  0.20479661]\n"," [0.8310019  0.16899814]\n"," [0.53017646 0.46982354]\n"," [0.92999214 0.07000791]\n"," [0.5354954  0.46450463]\n"," [0.32992488 0.6700751 ]\n"," [0.6487971  0.35120288]\n"," [0.44819596 0.55180407]\n"," [0.6048578  0.3951422 ]\n"," [0.38783753 0.6121625 ]\n"," [0.6446744  0.3553256 ]\n"," [0.3702751  0.62972486]\n"," [0.31400263 0.68599737]\n"," [0.45224148 0.5477586 ]\n"," [0.7218615  0.27813846]\n"," [0.91819316 0.0818069 ]\n"," [0.75675994 0.24324006]\n"," [0.36741066 0.63258934]\n"," [0.23103043 0.7689696 ]\n"," [0.70172006 0.29827994]\n"," [0.18762444 0.81237555]\n"," [0.83650845 0.16349153]\n"," [0.36860073 0.6313993 ]\n"," [0.5890497  0.4109503 ]\n"," [0.85969085 0.14030915]\n"," [0.29083598 0.7091641 ]\n"," [0.11574499 0.884255  ]\n"," [0.5639955  0.4360045 ]\n"," [0.5214189  0.47858107]\n"," [0.6055439  0.39445612]\n"," [0.40810648 0.5918935 ]\n"," [0.09557984 0.90442014]\n"," [0.47483042 0.5251696 ]\n"," [0.6154804  0.3845196 ]\n"," [0.71152955 0.28847048]\n"," [0.8961279  0.10387213]\n"," [0.09016435 0.90983564]\n"," [0.18757182 0.8124281 ]\n"," [0.995717   0.00428295]]\n"],"name":"stdout"}]}]}